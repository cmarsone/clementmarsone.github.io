---
layout: post
title: (Quantum) Dynamic programming
---

#### Aim: found an optimal solution for some combinatorial problem

### Motivations

*Shortest path*: DP offers a differents approach for solving COPs
- Let $ D = (V , A)$ a directed graph with arc ddistance $c_ e$, $e \in A and a root node $s \in V$ 
- > finding the shortest from a node $s$ to ecery other node $v \in V$

![image](https://user-images.githubusercontent.com/109908559/217756375-185fc715-ecb3-499f-8b89-4bbd048ddd50.png)

*Complexity* $=O(n^2)$

#### Induction
By increasing *k* from $1$ to $n − 1$ et en calculant à chaque fois
Dk (j), ∀j ∈ V par récurrence, on obtient un algorithme en O(mn) et
d(j) = Dn−1(j).
Cette approche où la solution optimale est calculée de manière
recursive à partir de la solution de problèmes légèrement différents
s’appelle la Programmation Dynamique.
On utilisera la terminologie suivante :

1. Principe d’optimalité : propriété que des parties de
solutions optimales sont elles mêmes optimales.
2. Etats : Noeuds pour lesquels il faut faire différentes
operations.
3. Etapes : étapes qui définissent l’ordre à suivre.

*Knapsack* : Assuming that th RHS $λ$ taking values
0, . . . , b represent les états et le sous ensemble de variables x1, . . . , xr ,
représenté par r , les étapes, on obtient le problème Pr (λ) suivant :
fr (λ) = max r∑
j=1
cj xj
s.c r∑
j=1
aj xj ≤ λ
x ∈ Br .
où fr (λ) est la valeur optimale de Pr (λ).
Ainsi z = fn(b) donne la valeur optimale du problème du sac-à-dos.

We therefore need to define a recurrence to calcukate £f_ r (λ)$ in terms of values $f_ s (μ)$ for $s ≤ r$
and $μ ≤ λ$.

What does une solution optimale x∗ meanpour le problème Pr (λ) ainsi que la valeur fr (λ) ?
Two possible cases : $x_ r^* = 0$ ou $x_ r^* = 1$
1. Si x∗ r = 0 alors fr (λ) = fr −1(λ) (by the same optmiality argument as for the shortest path).
2. Si x∗ r = 1 alors fr (λ) = cr + fr −1(λ − ar ).
Finally, we obtain the following formula:
$$f_ r (λ) = \max \{ f_ r −1 (λ), c_ r + f_ r −1 (λ − a_ r )\}$$

- Initializing the recurrence
Si on initialise la récurrence avec f0(λ) = 0 pour λ ≥ 0, ou
de manière équivalente avec f1(λ) = 0 pour 0 ≤ λ < a1 et
f1(λ) = max[c1, 0] pour λ ≥ a1, on peut poursuivre la
récurrence pour calculer f2, f3, . . . , fn pour toutes les
valeurs entières de λ de 0 à b.
- Initialization
1. fr (λ) = −∞, ∀r ≥ 0, λ < 0.
2. fr (0) = 0, ∀r ≥ 0.
3. f0(λ) = 0, ∀λ ≥ 0.

- Solution optimale (backtracking)

Comment obtenir la solution optimale du problème du sac-à-dos ?
Il faut réitérer à partir de la valeur optimale de fn (b). Deux cas possibles :
1 Store all values of fr (λ).
2 Use an indicator pr (λ) tel que :
pr (λ) = 0 si fr (λ) = fr −1(λ)
pr (λ) = 1 sinon.
3 Si pn(b) = 0 alors fn(b) = fn−1(b). On pose x∗
n = 0 et on
cherche une solution optimale qui a une valeur fn−1(b).
4 Si pn(b) = 1 alors fn(b) = cn + fn−1(b − an). On pose
x∗
n = 1 et we look for an optimal solution that has une valeur
fn−1(b − an).
En réitérant ce processus n fois, on obtient la solution optimale.

Solution optimale
If we count le nombre d’opérations élémentaires
nécessaires pour calculer z = fn(b), on notice que pour
chaque fr (λ), pour λ = 0, . . . , b et r = 1, . . . , n there is still
a constant nombre constant d’additions, de soustractions et de
comparaisons.
Hence, the complexity of the dynamic programming algorithm $O(nb)$.

Pour construire une récurrence, on procède de la même manière qu’en 0 − 1
Si x∗ est la solution optimale pour le problème Pr (λ) pour une valeur de gr (λ), alors on retiendra la valeur
de x∗
r .
1 Si x∗
r = t alors gr (λ) = cr t + gr −1(λ − t.ar ) pour
t = 0, . . . , b λ
ar c d’après le principe d’optimalité.
On a donc la formule de récurrence suivante :
gr (λ) = max
t=0,...,b λ
ar c
{cr .t + gr −1(λ − t.ar )} (4)
Comme b λ
ar c = b dans le plus mauvais cas, this result to an algorithm of complexité O(nb2 )
Peut-on améliorer cet algorithme ?
Est il possible de réduire le calcul de gr (λ) à une comparaison de deux cas ?






