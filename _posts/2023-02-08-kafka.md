---
layout: post
title: Kafka & Redis
author: from B. Groz course
---

### Data serialization framework (RPC)

*Protocol Buffers* (proto2, proto3): Google
- messages are key-value pairs
- define, in a file `.proto`, the message structure
- the message is then compiled in a programming language of choice
- compact format
- used by gRPC (gRPC+protobuf faster than Rest+JSON)

*Thrift*: Facebook then Apache
- we define a message structure then we compile it into an object
- more languages available than *Protocol Buffers* (?)
*Avro*: Apache
- schema defined in JSON, dynamic, not compiled


API

REST

#### Data exchange using REST APIs

*Representational state transfer* - Restful API contains:
- a resource description URI
- HTTP methods
- MIME types: JSON, XML, but also data structure (pages, sorting, ...) – can take considerable implementation effort

#### RPC API vs JSON HTTP API

RPC use cases:
- micro-services (RPC is low latency, high debit, so low network volume)
- streaming (real-time)
Disadvantages:
- cannot call services directly via HTTP (=browser)
- binary format, so not human readable

### Using a message broker - "courtier de messages"

*Publish & subscribe platforms*

Intermediary between providers and receivers (subscribers)
- exchange is simplified (providers and receivers are independent)
- allows asynchronous communication
Compared to RPC:
- no direct communication
- sometimes needs heavy architecture (Kafka vs. gRPC)
*message queue*: each message read once, or pub/sub – only subscribers are read

#### Example of message agent

- data streams
- guarantees receiving the message in the same order
- partitioning & replication
- objective: low latency, high debit

### Kafka

- data streams with low latency
- guarantees receiving the message in the same order (in the same partition)
- partitioning and replication
- objective: low latency, high debit

*Main role*: publish-subscribe system used as a “distributed commit/message log”
- activity streams, real-time data pipelines (Twitter)
- real-time event processing (Netflix)
- log delivery (Spotify)
- telemetry data (Mozilla)

*Actors*:
- data producers write data to brokers
- consumers read data from brokers distributed
*Data*:
- data is stored in topics
- each topic is split into partitions, which are replicated
- each partition is an ordered sequence of messages
- messages take the form of key-value pairs

*Real-time messaging*: clients assign offsets (what has been read) to topics and wait for new
messages to arrive

*Topics*:
- a topic is composed of partitions
- partition: ordered and immutable sequence of messages
- continually appended to
- number of partitions = consumer parallelism

*Replication*: back-ups of partitions
- only to prevent data loss
- never read from, never written to
- data loss when numReplicas − 1 are lost

### Principles of key-value stores

Reminder on principle of NoSQL:
trade availability for speed and scale
Simple data models are generally faster
Simplest data model – key-value:
key: short byte sequence (most often, integer)
value: long(er) byte sequence (e.g., string)
No query language – two main operations:
PUT(k,v)
GET(k)

#### Key-value data models

Simplest approach:
one value par key
But more complex approaches can exist:
organize so that key-value pairs belong to collections, tables or tables
multiple values per key
one key can be a list of attributes, where each attribute has a value

### ReDiS - REmote DIctionary Server (2009)

*Key*:
- printable ASCII
*Value*:
- strings (primitive type)
- hashes
- lists
- sets
- sorted sets

[Tutorial to learn Redis] (https://try.redis.io/)

#### System Architecture

*Redis Instance*:
- main memory database
- single-threaded event loop
*VM architecture*:
- organized in values, not pages
*Data Persistence*
- periodic dump in background
- append only file (on every write, append change to log file)

#### Redis vs. CAP Theorem

*Transactions*: commands serialized and executed sequentially, all commands
or no commands are processed, keys must specified in transactions

*Replication*: organized as a tree, data redundancy, master is unaware of slaves (only
the master needs to accept the write)

Consistency, Availability:
- writes via single master, any node reads, eventual consistency
Consistency, Partitioning:
- on failure: inhibit writes
Partitioning, Availability:
- on failure: elect new master
